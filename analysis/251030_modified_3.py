
import os
import warnings
warnings.filterwarnings("ignore", category=UserWarning)
warnings.filterwarnings("ignore", category=FutureWarning)

import pandas as pd
import geopandas as gpd
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from matplotlib import font_manager, rc
import contextily as cx
from shapely.ops import unary_union
try:
    import pulp
except ImportError:
    print("Pulp is not installed. Please install it using: pip install pulp")
    exit()

# --- 1. ê²½ë¡œ ë° ì„¤ì • (ìˆ˜ì •ë¨) ---

ROOT_DIR = "/Users/dongyounglee/Library/CloudStorage/GoogleDrive-dtsy5891@gmail.com/á„‚á…¢ á„ƒá…³á„…á…¡á„‹á…µá„‡á…³/Coursework/2025 á„á…®á†¼á„á…¥á†¼á„€á…¯á†«á„‹á…´ á„†á…µá„…á…¢"

# [ì…ë ¥] ê²©ì ë° ì¸êµ¬ ë°ì´í„° ê²½ë¡œ
SIG_SHAPE = os.path.join(ROOT_DIR, "250923/bnd_sigungu_00_2024_2Q/bnd_sigungu_00_2024_2Q.shp")
GRID_A = os.path.join(ROOT_DIR, "250923/_grid_border_grid_2024_grid_á„ƒá…¡á„‡á…¡_grid_á„ƒá…¡á„‡á…¡/grid_á„ƒá…¡á„‡á…¡_500M.shp")
GRID_B = os.path.join(ROOT_DIR, "250923/_grid_border_grid_2024_grid_á„…á…¡á„‡á…¡_grid_á„…á…¡á„‡á…¡/grid_á„…á…¡á„‡á…¡_500M.shp")
POP_A  = os.path.join(ROOT_DIR, "250923/_census_reqdoc_1758606603346/2023á„‚á…§á†«_á„‹á…µá†«á„€á…®_á„ƒá…¡á„‡á…¡_500M.txt")
POP_B  = os.path.join(ROOT_DIR, "250923/_census_reqdoc_1758606603346/2023á„‚á…§á†«_á„‹á…µá†«á„€á…®_á„…á…¡á„‡á…¡_500M.txt")

# [ì…ë ¥] ìƒí™œì²´ìœ¡ì‹œì„¤ ê³µê¸‰ ë°ì´í„° (í™œì„±í™”)
FACILITY_FILE = os.path.join(ROOT_DIR, "251019/python/analysis/cheongju_community_facilities.csv")

# [ì¶œë ¥] ê²°ê³¼ ë§µì´ ì €ì¥ë  í´ë”
FIG_DIR = "output_maps_v3"
os.makedirs(FIG_DIR, exist_ok=True)

# [ì„¤ì •] GTF í•˜ì´í¼íŒŒë¼ë¯¸í„°
LAMBDA = 1.0
STEPS = 500
LEARNING_RATE = 0.01

# [ì„¤ì •] ê³µê¸‰(Supply) ì •ì˜ (í™œì„±í™”)
BUFFER_RADIUS_METERS = 2000 # ì„œë¹„ìŠ¤ ê¶Œì—­ ë°˜ê²½ 2km
SUPPLY_EPSILON = 0.01       # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€

# [ì„¤ì •] ìµœì í™” ëª¨ë¸ íŒŒë¼ë¯¸í„° (ì‹ ê·œ ì¶”ê°€)
N_NEW_FACILITIES = 5  # ì‹ ê·œë¡œ ê±´ì„¤í•  ì‹œì„¤ì˜ ìˆ˜
CANDIDATE_THRESHOLD_PERCENTILE = 90  # í›„ë³´ì§€ ì„ ì • ê¸°ì¤€ (ìƒìœ„ %)
OPTIMIZATION_TARGET_COLUMN = 'gtf_smoothed' # ìµœì í™”ì— ì‚¬ìš©í•  GTF ê²°ê³¼ (gtf_smoothed ë˜ëŠ” gtf_residuals)


# -------------------------------------------------------------------------

def setup_korean_font():
    """Matplotlibì—ì„œ í•œê¸€ í°íŠ¸ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤."""
    try:
        font_name = font_manager.FontProperties(fname="c:/Windows/Fonts/malgun.ttf").get_name()
        rc('font', family=font_name)
        plt.rcParams['axes.unicode_minus'] = False
        print(f"Korean font '{font_name}' set up for plotting.")
    except:
        print("Korean font not found. Skipping font setup.")

def load_demand_and_grid(sig_path, grid_paths, pop_paths):
    """
    Sigungu, Grid, Population ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  Cheongju ì§€ì—­ìœ¼ë¡œ í´ë¦¬í•‘í•©ë‹ˆë‹¤.
    """
    print("Loading sigungu shapefile...")
    sig = gpd.read_file(sig_path)
    cheongju_codes = ["33041", "33042", "33043", "33044"]
    cheongju_one = sig[sig["SIGUNGU_CD"].isin(cheongju_codes)].dissolve()

    print("Loading grid shapefiles...")
    gdfs = [gpd.read_file(path) for path in grid_paths]
    grid_all = pd.concat(gdfs, ignore_index=True)

    if grid_all.crs != cheongju_one.crs:
        grid_all = grid_all.to_crs(cheongju_one.crs)

    if "GRID_500M_" in grid_all.columns:
        grid_all = grid_all.rename(columns={"GRID_500M_": "gid"})
    elif "GRID_500M" in grid_all.columns:
        grid_all = grid_all.rename(columns={"GRID_500M": "gid"})

    grid_all["gid"] = grid_all["gid"].astype(str).str.strip()
    grid_all = grid_all.dropna(subset=["gid"])
    grid_all_unique = grid_all.drop_duplicates(subset='gid')

    print("Clipping grid to Cheongju area...")
    grid_cj = gpd.clip(grid_all_unique, cheongju_one)
    grid_cj = grid_cj.set_index('gid')

    print("Loading population text files...")
    pop_dfs = []
    for path in pop_paths:
        try:
            df = pd.read_csv(path, sep='^', header=None, names=['year', 'gid', 'type', 'pop'], dtype={'gid': str})
        except UnicodeDecodeError:
            df = pd.read_csv(path, sep='^', header=None, names=['year', 'gid', 'type', 'pop'], encoding='cp949', dtype={'gid': str})
        pop_dfs.append(df)
    pop_df = pd.concat(pop_dfs, ignore_index=True)
    pop_df['gid'] = pop_df['gid'].str.strip()

    total_pop_df = pop_df[pop_df['type'] == 'to_in_001'].pivot(index='gid', columns='type', values='pop').fillna(0)
    total_pop_df.columns = ['total_pop']
    total_pop_df['total_pop'] = pd.to_numeric(total_pop_df['total_pop'], errors='coerce').fillna(0)

    grid_pop = grid_cj.join(total_pop_df, how='left').fillna(0)
    print(f"Loaded and processed {len(grid_pop)} grid cells for Cheongju.")
    return grid_pop

def calculate_supply(grid_gdf, facility_path, buffer_radius_m):
    """
    ìƒí™œì²´ìœ¡ì‹œì„¤ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê° ê²©ì(grid)ì˜ ê³µê¸‰ ë¹„ìœ¨(0~1)ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
    """
    print(f"Calculating supply based on '{facility_path}'...")
    facilities_df = pd.read_csv(facility_path)
    facilities_gdf = gpd.GeoDataFrame(
        facilities_df, 
        geometry=gpd.points_from_xy(facilities_df.lon, facilities_df.lat),
        crs="EPSG:4326"
    )
    
    facilities_gdf = facilities_gdf.to_crs(grid_gdf.crs)
    
    print(f"Creating {buffer_radius_m}m buffers for {len(facilities_gdf)} facilities...")
    buffers = facilities_gdf.geometry.buffer(buffer_radius_m)
    all_buffers_union = unary_union(buffers)
    
    grid_gdf['grid_area'] = grid_gdf.geometry.area
    
    print("Calculating intersection area (this may take a moment)...")
    intersection_area = grid_gdf.geometry.intersection(all_buffers_union).area
    
    grid_gdf['supply_ratio'] = (intersection_area / grid_gdf['grid_area']).fillna(0)
    grid_gdf['supply_ratio'] = grid_gdf['supply_ratio'].clip(0, 10)
    
    print("Supply calculation complete.")
    return grid_gdf

def build_graph(grid_gdf):
    """
    GeoDataFrameì—ì„œ ì¸ì ‘ì„±(Queen)ì„ ê¸°ë°˜ìœ¼ë¡œ ê·¸ë˜í”„ ì—£ì§€ë¥¼ êµ¬ì¶•í•©ë‹ˆë‹¤. (ìˆ˜ì •ëœ ë²„ì „)
    """
    print("Building graph (spatial join)...")
    grid_gdf_reset = grid_gdf.reset_index()
    N = len(grid_gdf_reset)
    neighbors = gpd.sjoin(grid_gdf_reset, grid_gdf_reset, how="inner", predicate="touches")
    neighbors = neighbors[neighbors.index != neighbors['index_right']]
    senders = neighbors.index.values
    receivers = neighbors['index_right'].values
    E = len(senders)
    print(f"Graph built: {N} nodes, {E} edges.")
    return N, E, senders, receivers

def run_gtf_gpu(y_signal_tf, N, E, senders, receivers, lambda_val, steps, learning_rate):
    """
    TensorFlow (GPU)ë¥¼ ì‚¬ìš©í•˜ì—¬ GTF ìµœì í™”ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    print("Running GTF optimization on GPU...")
    beta = tf.Variable(tf.zeros(N, dtype=tf.float32), name="beta")
    optimizer = tf.optimizers.Adam(learning_rate=learning_rate)
    
    @tf.function
    def train_step():
        with tf.GradientTape() as tape:
            loss_fidelity = tf.reduce_sum(tf.square(y_signal_tf - beta)) * 0.5
            beta_i = tf.gather(beta, senders)
            beta_j = tf.gather(beta, receivers)
            loss_penalty = lambda_val * tf.reduce_sum(tf.abs(beta_i - beta_j))
            total_loss = loss_fidelity + loss_penalty
        gradients = tape.gradient(total_loss, [beta])
        optimizer.apply_gradients(zip(gradients, [beta]))
        return total_loss

    for step in range(steps):
        loss = train_step()
        if (step + 1) % (steps // 10) == 0:
            print(f"Step {step+1}/{steps}, Loss: {loss.numpy():.2f}")
    print("GTF optimization complete.")
    return beta.numpy()

def plot_and_save(gdf, column, cmap, filename, vmin=None, vmax=None): # vmin, vmax ì¶”ê°€
    """ê²°ê³¼ ë§µì„ í”Œë¡œíŒ…í•˜ê³  ì €ì¥í•©ë‹ˆë‹¤. (ìˆ˜ì •ë¨: vmin, vmax ì§€ì›)"""
    print(f"Plotting and saving: {filename}")
    fig, ax = plt.subplots(1, 1, figsize=(10, 10))
    gdf_3857 = gdf.to_crs(epsg=3857)
    
    gdf_3857.plot(
        column=column, 
        cmap=cmap, 
        legend=True, 
        ax=ax, 
        alpha=0.7,
        legend_kwds={'shrink': 0.8},
        vmin=vmin,  # â—ï¸ ìŠ¤ì¼€ì¼ ê³ ì •ì„ ìœ„í•´ ì¶”ê°€
        vmax=vmax   # â—ï¸ ìŠ¤ì¼€ì¼ ê³ ì •ì„ ìœ„í•´ ì¶”ê°€
    )
    
    ax.set_axis_off()
    cx.add_basemap(ax, crs=gdf_3857.crs.to_string(), source=cx.providers.CartoDB.Positron)
    plt.savefig(os.path.join(FIG_DIR, filename), dpi=300, bbox_inches='tight')
    plt.close(fig)

def run_location_optimization(grid_gdf, n_facilities, candidate_col, threshold_percentile, service_radius_m):
    """
    MCLP (Maximal Covering Location Problem) ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ìµœì ì˜ ì‹ ê·œ ì‹œì„¤ ì…ì§€ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    (ì´ì „ LSCP ì£¼ì„ì„ MCLPë¡œ ìˆ˜ì •)
    """
    print("\n--- Running Location Optimization (MCLP) ---")
    
    # ğŸ’¡ [í•´ê²°ì±… 1] ì‚¬ìš©í•  'ë¯¸í„°(m) ê¸°ë°˜' íˆ¬ì˜ ì¢Œí‘œê³„ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. (ì˜ˆ: EPSG:5179)
    PROJ_CRS = "EPSG:5179" 
    
    # 1. ìˆ˜ìš”ì§€(Demand Points) ì •ì˜
    demand_points = grid_gdf[grid_gdf['total_pop'] > 0].copy()
    # ğŸ’¡ [í•´ê²°ì±… 2] ìˆ˜ìš”ì§€ë¥¼ ë¯¸í„° ê¸°ë°˜ ì¢Œí‘œê³„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    demand_points = demand_points.to_crs(PROJ_CRS)
    demand_points['demand_id'] = range(len(demand_points))
    print(f"Defined {len(demand_points)} demand points (grids with population > 0).")

    # 2. í›„ë³´ì§€(Candidate Sites) ì„ ì •
    threshold_value = np.percentile(grid_gdf[candidate_col], threshold_percentile)
    candidate_sites = grid_gdf[grid_gdf[candidate_col] >= threshold_value].copy()
    # ğŸ’¡ [í•´ê²°ì±… 3] í›„ë³´ì§€ë¥¼ ë¯¸í„° ê¸°ë°˜ ì¢Œí‘œê³„ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    candidate_sites = candidate_sites.to_crs(PROJ_CRS)
    candidate_sites['candidate_id'] = range(len(candidate_sites))
    print(f"Selected {len(candidate_sites)} candidate sites (top {100-threshold_percentile}% of '{candidate_col}').")

    # í›„ë³´ì§€ gidë¥¼ candidate_idë¡œ ë§¤í•‘í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ìƒì„±
    # (ì´ì œ candidate_sitesì˜ ì¸ë±ìŠ¤(gid)ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤)
    gid_to_candidate_id = pd.Series(candidate_sites.candidate_id.values, index=candidate_sites.index).to_dict()

    # 3. ì»¤ë²„ë¦¬ì§€ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
    print(f"Creating coverage matrix (service radius: {service_radius_m}m)...")
    
    # í›„ë³´ì§€ì˜ ë²„í¼ë¥¼ ìƒì„± (ì´ì œ PROJ_CRS ìƒì—ì„œ 2000 'ë¯¸í„°' ë²„í¼ê°€ ì •í™•íˆ ìƒì„±ë¨)
    candidate_buffers_gdf = candidate_sites.copy()
    candidate_buffers_gdf.geometry = candidate_sites.geometry.buffer(service_radius_m)
    # (ë²„í¼ í›„ CRSê°€ ì†ì‹¤ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ëª…ì‹œì ìœ¼ë¡œ ì¬í• ë‹¹)
    candidate_buffers_gdf.crs = PROJ_CRS

    # sjoinì„ ì‚¬ìš© (ì´ì œ demand_pointsì™€ candidate_buffers_gdf ëª¨ë‘ ë™ì¼í•œ PROJ_CRSë¥¼ ê°€ì§)
    coverage = gpd.sjoin(demand_points, candidate_buffers_gdf, how='inner', predicate='intersects')
    
    if coverage.empty:
        print("\n[!!!] CRITICAL ERROR: sjoin returned an empty result even with CRS projection.")
        print("Please check if candidate/demand points are in the same region.")
        return gpd.GeoDataFrame() 

    # ê° ìˆ˜ìš”ì§€(demand_id)ë¥¼ ì»¤ë²„í•˜ëŠ” í›„ë³´ì§€(gid) ë¦¬ìŠ¤íŠ¸ ìƒì„±
    # (coverageì˜ index_rightì—ëŠ” candidate_buffers_gdfì˜ ì¸ë±ìŠ¤(gid)ê°€ ì €ì¥ë©ë‹ˆë‹¤)
    coverage_dict = coverage.groupby('demand_id')['gid_right'].apply(list).to_dict()

    # 4. ìµœì í™” ëª¨ë¸ ìˆ˜ë¦½ (PuLP)
    print("Setting up PuLP optimization model...")
    prob = pulp.LpProblem("Facility_Location_MCLP", pulp.LpMaximize)

    # ê²°ì • ë³€ìˆ˜
    x = pulp.LpVariable.dicts("x", candidate_sites['candidate_id'].to_list(), cat='Binary')
    y = pulp.LpVariable.dicts("y", [d['demand_id'] for _, d in demand_points.iterrows()], cat='Binary')

    # ëª©ì  í•¨ìˆ˜: ì»¤ë²„ë˜ëŠ” ì´ ì¸êµ¬ìˆ˜ ìµœëŒ€í™”
    # (demand_pointsê°€ projectedë˜ì—ˆìœ¼ë¯€ë¡œ .loc[]ë¥¼ ì‚¬ìš©í•˜ì—¬ ì •í™•í•œ ì¸êµ¬ ì°¸ì¡°)
    demand_pop_dict = pd.Series(demand_points.total_pop.values, index=demand_points.demand_id).to_dict()
    prob += pulp.lpSum([demand_pop_dict[i] * y[i] for i in y]), "Total_Covered_Population"

    # ì œì•½ ì¡°ê±´
    # 1) ì‹ ê·œ ì‹œì„¤ì€ ì •í™•íˆ Nê°œë§Œ ê±´ì„¤
    prob += pulp.lpSum([x[j] for j in x]) == n_facilities, "Num_Facilities_Constraint"

    # 2) ìˆ˜ìš”ì§€ iê°€ ì»¤ë²„ë˜ë ¤ë©´, ê·¸ ìˆ˜ìš”ì§€ë¥¼ ì»¤ë²„í•˜ëŠ” í›„ë³´ì§€ ì¤‘ ì ì–´ë„ í•˜ë‚˜ì— ì‹œì„¤ì´ ê±´ì„¤ë˜ì–´ì•¼ í•¨
    for i in y:
        candidate_gids_for_demand_i = coverage_dict.get(i, [])
        if candidate_gids_for_demand_i:
            # gidë¥¼ candidate_idë¡œ ë³€í™˜
            candidate_ids_for_demand_i = [gid_to_candidate_id[gid] for gid in candidate_gids_for_demand_i if gid in gid_to_candidate_id]
            
            if candidate_ids_for_demand_i: 
                 prob += y[i] <= pulp.lpSum([x[j] for j in candidate_ids_for_demand_i]), f"Coverage_Constraint_{i}"
            else:
                 prob += y[i] == 0 
        else:
            prob += y[i] == 0

    # 5. ëª¨ë¸ ì‹¤í–‰
    print("Solving optimization problem...")
    prob.solve()
    print(f"Solver status: {pulp.LpStatus[prob.status]}")
    
    if prob.status != pulp.LpStatusOptimal:
        print("[!!!] Optimization FAILED or was not optimal.")
        return gpd.GeoDataFrame()

    # 6. ê²°ê³¼ ì¶”ì¶œ
    optimal_sites_indices = [j for j in x if x[j].varValue > 0.9]
    optimal_sites_proj = candidate_sites[candidate_sites['candidate_id'].isin(optimal_sites_indices)]
    
    # ğŸ’¡ [í•´ê²°ì±… 4] ìµœì¢… ê²°ê³¼ë¥¼ ì›ë˜ ì¢Œí‘œê³„ë¡œ ë˜ëŒë ¤ ì‹œê°í™”ì— ì‚¬ìš©í•©ë‹ˆë‹¤.
    optimal_sites = optimal_sites_proj.to_crs(grid_gdf.crs)
    
    total_pop = demand_points['total_pop'].sum()
    covered_pop = pulp.value(prob.objective)
    coverage_percentage = (covered_pop / total_pop) * 100 if total_pop > 0 else 0
    
    print(f"\nOptimization Results:")
    print(f" - Selected {len(optimal_sites)} new facility locations.")
    print(f" - Total population in Cheongju grids: {total_pop:,.0f}")
    print(f" - Population covered by new facilities: {covered_pop:,.0f}")
    print(f" - Coverage percentage: {coverage_percentage:.2f}%")
    
    return optimal_sites

def plot_optimization_results(base_gdf, existing_facilities_path, new_facility_sites, target_col, filename):
    """ìµœì í™” ê²°ê³¼ë¥¼ ì‹œê°í™”í•©ë‹ˆë‹¤. (ìˆ˜ì •ë¨: ë§ˆì»¤ ì¼ì¹˜, ì œëª© ì œê±°)"""
    print(f"Plotting and saving optimization results: {filename}")
    
    # ê¸°ì¡´ ì‹œì„¤ ë¡œë“œ
    existing_fac_df = pd.read_csv(existing_facilities_path)
    existing_fac_gdf = gpd.GeoDataFrame(
        existing_fac_df, 
        geometry=gpd.points_from_xy(existing_fac_df.lon, existing_fac_df.lat),
        crs="EPSG:4326"
    )
    
    fig, ax = plt.subplots(1, 1, figsize=(12, 12))
    base_gdf_3857 = base_gdf.to_crs(epsg=3857)
    existing_fac_3857 = existing_fac_gdf.to_crs(epsg=3857)
    
    # â—ï¸ new_facility_sitesê°€ ë¹„ì–´ìˆëŠ” ê²½ìš°(ìµœì í™” ì‹¤íŒ¨ ë“±)ë¥¼ ëŒ€ë¹„
    if not new_facility_sites.empty:
        new_sites_3857 = new_facility_sites.to_crs(epsg=3857)
    else:
        # ë¹„ì–´ìˆëŠ” GeoDataFrameì„ ìƒì„±í•˜ì—¬ ì˜¤ë¥˜ ë°©ì§€
        new_sites_3857 = gpd.GeoDataFrame(geometry=[], crs="EPSG:3857")


    # 1. ë°°ê²½ ì§€ë„ (GTF ê²°ê³¼)
    base_gdf_3857.plot(
        column=target_col, cmap='OrRd', legend=True, ax=ax, alpha=0.7,
        legend_kwds={'shrink': 0.8, 'label': f"Potential Score ({target_col})"}
    )
    
    # 2. ê¸°ì¡´ ì‹œì„¤ ìœ„ì¹˜
    existing_fac_3857.plot(ax=ax, marker='o', color='blue', markersize=30, label='Existing Facilities', alpha=0.8, edgecolor='white', zorder=5)

    # 3. ìµœì  ì‹ ê·œ ì…ì§€ (â—ï¸ìˆ˜ì •ëœ ë¶€ë¶„)
    # .centroidë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë¦¬ê³¤ì´ ì•„ë‹Œ ì¤‘ì‹¬ì ì— ë§ˆì»¤ë¥¼ ì°ë„ë¡ ìˆ˜ì •
    if not new_sites_3857.empty:
        new_sites_3857.centroid.plot(
            ax=ax, 
            marker='*', 
            color='red', 
            markersize=200, 
            label='Optimal New Locations', 
            edgecolor='black',
            zorder=10  # â—ï¸ zorderë¥¼ ì¶”ê°€í•˜ì—¬ í•­ìƒ ìœ„ì— ë³´ì´ë„ë¡ í•¨
        )

    # ax.set_title(f'Optimal Locations for {len(new_facility_sites)} New Facilities') # â—ï¸ ìš”ì²­ì— ë”°ë¼ ì œëª© ì œê±°
    ax.set_axis_off()
    cx.add_basemap(ax, crs=base_gdf_3857.crs.to_string(), source=cx.providers.CartoDB.Positron)
    
    # ë²”ë¡€ í•¸ë“¤ ìƒì„±
    from matplotlib.lines import Line2D
    legend_elements = [
        Line2D([0], [0], marker='o', color='w', label='Existing Facilities', markerfacecolor='blue', markersize=10),
        Line2D([0], [0], marker='*', color='w', label='Optimal New Locations', markerfacecolor='red', markersize=15, markeredgecolor='black')
    ]
    ax.legend(handles=legend_elements, loc='lower right', fontsize=12)

    plt.savefig(os.path.join(FIG_DIR, filename), dpi=300, bbox_inches='tight')
    plt.close(fig)
    
    
    
# --- 4. Main ì‹¤í–‰ ë¡œì§ ---
def main():
    setup_korean_font()
    
    # 1. ìˆ˜ìš”(Demand) ë° ê²©ì(Grid) ë¡œë“œ
    grid_pop = load_demand_and_grid(SIG_SHAPE, [GRID_A, GRID_B], [POP_A, POP_B])
    
    # 2. ê³µê¸‰(Supply) ê³„ì‚° (í™œì„±í™”)
    grid_pop = calculate_supply(grid_pop, FACILITY_FILE, BUFFER_RADIUS_METERS)
    
    # 3. ê·¸ë˜í”„(Graph) êµ¬ì¶•
    (N, E, senders, receivers) = build_graph(grid_pop)
    
    # 4. ìµœì¢… ë¶ˆê· í˜• ì‹ í˜¸(Y) ì •ì˜ (ìˆ˜ìš”/ê³µê¸‰ ëª¨ë‘ ì‚¬ìš©)
    demand = grid_pop['total_pop'].values
    supply = grid_pop['supply_ratio'].values
    y_signal = np.log1p(demand) - np.log(supply + SUPPLY_EPSILON)
    y_signal[demand == 0] = 0 
    grid_pop['y_imbalance'] = y_signal
    
    # 5. GTF ëª¨ë¸ ì‹¤í–‰ (GPU)
    y_signal_tf = tf.constant(y_signal, dtype=tf.float32)
    beta_smoothed = run_gtf_gpu(
        y_signal_tf, N, E, senders, receivers, 
        LAMBDA, STEPS, LEARNING_RATE
    )
    
    # 6. ê²°ê³¼ ì €ì¥
    grid_pop['gtf_smoothed'] = beta_smoothed
    grid_pop['gtf_residuals'] = y_signal - beta_smoothed
    
    # --- 7. ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥ (â—ï¸ ìŠ¤ì¼€ì¼ í†µì¼ ì‘ì—…) ---
    
    print("Saving sequential maps (1, 2, 4) with 'OrRd' colormap...")
    # (1, 2, 4ë²ˆì€ ë¶‰ì€ ê³„ì—´ ìœ ì§€)
    plot_and_save(grid_pop, 'total_pop', 'OrRd', '01_original_demand.png') 
    plot_and_save(grid_pop, 'supply_ratio', 'OrRd', '02_original_supply.png')
    plot_and_save(grid_pop, 'gtf_smoothed', 'OrRd', '04_GTF_Beta_Hotspots.png')

    # â—ï¸ [ì‹ ê·œ] 3ë²ˆê³¼ 5ë²ˆì˜ ìŠ¤ì¼€ì¼ í†µì¼ì„ ìœ„í•œ ìµœëŒ€ ì ˆëŒ€ê°’ ê³„ì‚°
    print("Calculating unified scale for diverging maps (3, 5)...")
    all_diverging_values = pd.concat([grid_pop['y_imbalance'], grid_pop['gtf_residuals']])
    v_abs_max = all_diverging_values.abs().max()
    print(f"Unified scale set to: vmin={-v_abs_max:.2f}, vmax={v_abs_max:.2f}")

    # â—ï¸ [ìˆ˜ì •] 3ë²ˆê³¼ 5ë²ˆ í”Œë¡¯ ì €ì¥ (cmap ë³µì› ë° vmin/vmax ì ìš©)
    
    # â—ï¸ 3ë²ˆ: 'coolwarm' ë³µì›, ìŠ¤ì¼€ì¼ ê³ ì •
    plot_and_save(
        grid_pop, 'y_imbalance', 'coolwarm', '03_original_imbalance_Y.png',
        vmin=-v_abs_max, 
        vmax=v_abs_max
    )
    
    # â—ï¸ 5ë²ˆ: 'coolwarm' ë³µì›, ìŠ¤ì¼€ì¼ ê³ ì •
    plot_and_save(
        grid_pop, 'gtf_residuals', 'coolwarm', '05_GTF_Residuals_Pockets.png',
        vmin=-v_abs_max, 
        vmax=v_abs_max
    )
    # (ì°¸ê³ : ê¸°ì¡´ 5ë²ˆ 'PuOr' ëŒ€ì‹  'coolwarm'ìœ¼ë¡œ í†µì¼)

    # --- 8. ì‹ ê·œ: ìµœì  ì…ì§€ ë¶„ì„ ë° ì‹œê°í™” ---
    optimal_locations = run_location_optimization(
        grid_gdf=grid_pop,
        n_facilities=N_NEW_FACILITIES,
        candidate_col=OPTIMIZATION_TARGET_COLUMN,
        threshold_percentile=CANDIDATE_THRESHOLD_PERCENTILE,
        service_radius_m=BUFFER_RADIUS_METERS
    )

    print("\n\n--- ğŸ“ ìµœì¢… ì„ ì •ëœ ìµœì  ì…ì§€ (ìˆ˜ë™ í™•ì¸) ğŸ“ ---")
    if optimal_locations.empty:
        print(" [ê²°ê³¼] ìµœì í™”ì— ì‹¤íŒ¨í–ˆê±°ë‚˜ ì„ ì •ëœ ì…ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print(f" [ê²°ê³¼] ì´ {len(optimal_locations)}ê°œì˜ ìµœì  ì…ì§€ë¥¼ ì„ ì •í–ˆìŠµë‹ˆë‹¤.")
        
        # 1. ì„ ì •ëœ ê²©ìì˜ GID (ê³ ìœ  ID)
        print("\n [1. ì„ ì •ëœ ê²©ì GID]")
        print(list(optimal_locations.index))
        
        # 2. ì„ ì •ëœ ê²©ìì˜ ì£¼ìš” ë°ì´í„° (GTF ì ìˆ˜, ì¸êµ¬ ë“±)
        print("\n [2. ì„ ì •ëœ ê²©ì ìƒì„¸ ì •ë³´]")
        print(optimal_locations[[OPTIMIZATION_TARGET_COLUMN, 'total_pop', 'y_imbalance', 'supply_ratio']])
        
        # 3. êµ¬ê¸€ë§µ ë“±ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆëŠ” ìœ„ë„/ê²½ë„ ì¢Œí‘œ (ì¤‘ì‹¬ì )
        try:
            print("\n [3. ì„ ì •ëœ ê²©ì ì¤‘ì‹¬ ìœ„ë„/ê²½ë„ (EPSG:4326)]")
            optimal_locations_4326 = optimal_locations.to_crs(epsg=4326)
            for gid, row in optimal_locations_4326.iterrows():
                print(f" - GID {gid}: (Lat: {row.geometry.centroid.y:.6f}, Lon: {row.geometry.centroid.x:.6f})")
            print("   (ìœ„ ì£¼ì†Œë¥¼ ë³µì‚¬í•˜ì—¬ êµ¬ê¸€ë§µì— 'ìœ„ë„, ê²½ë„' í˜•ì‹ìœ¼ë¡œ ë¶™ì—¬ë„£ê¸°)")
                
        except Exception as e:
            print(f"   (ìœ„ë„/ê²½ë„ ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e})")
            
    print("------------------------------------------------------\n\n")
    # ================================================================

    plot_optimization_results(
        base_gdf=grid_pop,
        existing_facilities_path=FACILITY_FILE,
        new_facility_sites=optimal_locations,
        target_col=OPTIMIZATION_TARGET_COLUMN,
        filename=f'06_Optimized_{N_NEW_FACILITIES}_New_Locations.png'
    )

    print(f"\n--- ëª¨ë“  ë¶„ì„ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. '{FIG_DIR}' í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”. ---")
    
    
    

if __name__ == "__main__":
    gpus = tf.config.experimental.list_physical_devices('GPU')
    if gpus:
        try:
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
            print(f"Running on {len(gpus)} GPU(s).")
        except RuntimeError as e:
            print(e)
    else:
        print("Running on CPU.")
    main()
